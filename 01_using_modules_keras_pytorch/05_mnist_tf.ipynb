{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(Model):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = Dense(hidden_dim, activation='sigmoid')\n",
    "        self.l2 = Dense(hidden_dim, activation = 'sigmoid')\n",
    "        self.l3 = Dense(hidden_dim, activation = 'sigmoid')\n",
    "        self.l4 = Dense(output_dim, activation = 'softmax')\n",
    "        self.ls = [self.l1, self.l2, self.l3, self.l4]\n",
    "    \n",
    "    def call(self, x):\n",
    "        for layer in self.ls:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.mnist\n",
    "(x_train, t_train), (x_test, t_test) = mnist.load_data()\n",
    "\n",
    "x_train = (x_train.reshape(-1, 784)/255).astype(np.float32)\n",
    "x_test  = (x_test.reshape(-1, 784)/ 255).astype(np.float32)\n",
    "t_train = np.eye(10)[t_train].astype(np.float32)\n",
    "t_test  = np.eye(10)[t_test].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN(200, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:2.3, acc:0.115\n",
      "epoch:2, loss:2.3, acc:0.121\n",
      "epoch:3, loss:2.3, acc:0.126\n",
      "epoch:4, loss:2.29, acc:0.132\n",
      "epoch:5, loss:2.29, acc:0.139\n",
      "epoch:6, loss:2.29, acc:0.147\n",
      "epoch:7, loss:2.28, acc:0.158\n",
      "epoch:8, loss:2.28, acc:0.173\n",
      "epoch:9, loss:2.27, acc:0.190\n",
      "epoch:10, loss:2.27, acc:0.209\n",
      "epoch:11, loss:2.26, acc:0.229\n",
      "epoch:12, loss:2.24, acc:0.247\n",
      "epoch:13, loss:2.22, acc:0.264\n",
      "epoch:14, loss:2.18, acc:0.282\n",
      "epoch:15, loss:2.14, acc:0.300\n",
      "epoch:16, loss:2.09, acc:0.320\n",
      "epoch:17, loss:2.04, acc:0.339\n",
      "epoch:18, loss:1.98, acc:0.357\n",
      "epoch:19, loss:1.93, acc:0.375\n",
      "epoch:20, loss:1.88, acc:0.391\n",
      "epoch:21, loss:1.83, acc:0.407\n",
      "epoch:22, loss:1.79, acc:0.423\n",
      "epoch:23, loss:1.74, acc:0.437\n",
      "epoch:24, loss:1.7, acc:0.451\n",
      "epoch:25, loss:1.66, acc:0.464\n",
      "epoch:26, loss:1.62, acc:0.477\n",
      "epoch:27, loss:1.59, acc:0.489\n",
      "epoch:28, loss:1.56, acc:0.500\n",
      "epoch:29, loss:1.52, acc:0.511\n",
      "epoch:30, loss:1.49, acc:0.522\n"
     ]
    }
   ],
   "source": [
    "criterion = losses.CategoricalCrossentropy()\n",
    "optimizer = optimizers.SGD(learning_rate = 0.01)\n",
    "train_loss = metrics.Mean()\n",
    "train_acc = metrics.CategoricalAccuracy()\n",
    "\n",
    "def compute_loss(t, y):\n",
    "    return criterion(t, y)\n",
    "\n",
    "def train_step(x, t):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(x)\n",
    "        loss = compute_loss(t, preds)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_acc(t, preds)\n",
    "    return loss\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "n_batches = x_train.shape[0] // batch_size\n",
    "for epoch in range(epochs):\n",
    "    x_, t_ = shuffle(x_train, t_train)\n",
    "    \n",
    "    for batch in range(n_batches):\n",
    "        start = batch * batch_size\n",
    "        end   = start + batch_size\n",
    "        train_step(x_[start:end], t_[start:end])\n",
    "    \n",
    "    print('epoch:{}, loss:{:.3}, acc:{:.3f}'.format(epoch+1, train_loss.result(), train_acc.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:0.587, test_acc:0.830\n"
     ]
    }
   ],
   "source": [
    "test_loss = metrics.Mean()\n",
    "test_acc = metrics.CategoricalAccuracy()\n",
    "\n",
    "def test_step(x, t):\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t, preds)\n",
    "    test_loss(loss)\n",
    "    test_acc(t, preds)\n",
    "    return loss\n",
    "\n",
    "test_step(x_test, t_test)\n",
    "\n",
    "print('test_loss:{:.3f}, test_acc:{:.3f}'.format(\n",
    "test_loss.result(),\n",
    "test_acc.result()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
